import torch
import torch.nn.functional as F
from transformers import AutoTokenizer

from model import NutrientClassifier
from survey_questions import SURVEY_QUESTIONS
from build_input import build_model_input


# ======================
# ì„¤ì •
# ======================
MODEL_PATH = "model.pt"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

LABEL_MAP = {
    0: "ë¹„íƒ€ë¯¼ D",
    1: "ë§ˆê·¸ë„¤ìŠ˜",
    2: "ì˜¤ë©”ê°€-3",
    3: "ë¹„íƒ€ë¯¼ B12",
    4: "ì² ë¶„",
    5: "ì•„ì—°",
    6: "ì¹¼ìŠ˜",
    7: "í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤",
    8: "ë¹„íƒ€ë¯¼ C",
    9: "ë°€í¬ì‹œìŠ¬",
}


# ======================
# ì„¤ë¬¸ ì…ë ¥ í•¨ìˆ˜
# ======================
def run_survey():
    responses = {}

    print("\nğŸ“ ê±´ê°• ì„¤ë¬¸ì„ ì‹œì‘í•©ë‹ˆë‹¤ (1~5 ìˆ«ì ì…ë ¥)\n")

    for idx, q in enumerate(SURVEY_QUESTIONS, 1):
        print(f"\nQ{idx}. {q['question']}")
        for i, option in enumerate(q["options"], 1):
            print(f"  {i}. {option}")

        while True:
            try:
                choice = int(input("ì„ íƒ: "))
                if 1 <= choice <= 5:
                    responses[q["key"]] = choice
                    break
                else:
                    print("âš ï¸ 1~5 ì‚¬ì´ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except ValueError:
                print("âš ï¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    return responses


# ======================
# ëª¨ë¸ ë¡œë“œ
# ======================
tokenizer = AutoTokenizer.from_pretrained(
    "monologg/kobert",
    trust_remote_code=True
)

model = NutrientClassifier()
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.to(DEVICE)
model.eval()


# ======================
# ì‹¤í–‰ë¶€ (ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸)
# ======================
if __name__ == "__main__":

    print("\nğŸ¥— ì˜ì–‘ì†Œ ì¶”ì²œ ì„¤ë¬¸ ëª¨ë¸\n")

    # 1ï¸âƒ£ ì„¤ë¬¸ ì§„í–‰
    responses = run_survey()

    # 2ï¸âƒ£ ì„¤ë¬¸ â†’ ë¬¸ì¥ ë³€í™˜
    input_text = build_model_input(responses)

    print("\nğŸ“„ ëª¨ë¸ ì…ë ¥ ë¬¸ì¥:")
    print(input_text)

    # 3ï¸âƒ£ ëª¨ë¸ ì¶”ë¡ 
    inputs = tokenizer(
        input_text,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=128
    ).to(DEVICE)

    with torch.no_grad():
        logits = model(
            input_ids=inputs["input_ids"],
            attention_mask=inputs["attention_mask"]
        )
        probs = F.softmax(logits, dim=1).squeeze()

    # 4ï¸âƒ£ TOP-3 ì¶œë ¥
    topk = torch.topk(probs, k=3)

    print("\nğŸ‘‰ ì¶”ì²œ ì˜ì–‘ì†Œ TOP 3:")
    for rank, (idx, score) in enumerate(zip(topk.indices, topk.values), start=1):
        label = LABEL_MAP[idx.item()]
        print(f"{rank}ï¸âƒ£ {label:<10} (ì‹ ë¢°ë„ {score.item():.2f})")
